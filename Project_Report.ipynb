{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "dd4a3e8c-22d6-44ed-a882-067fa9121509",
   "metadata": {},
   "source": [
    "# The Classification of Pulsar Stars - Project Report\n",
    "**By Oliver Gullery, Chan Le, Simon Lin, and Adam Parolin**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da135ffa-db66-40f1-a75b-5bde5dd14b3e",
   "metadata": {},
   "source": [
    "### Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69253e97-554c-439b-8c46-e9f308b40b47",
   "metadata": {},
   "source": [
    "Pulsar stars are a rare type of neutron star that produce detectable radio emissions. Pulsars rotate and emit beams of electromagnetic radiation, which can be detected if they align directly with Earth. \n",
    "\n",
    "These beams take the form of radio waves - electromagnetic waves oscillating at specific frequencies that can be detected.\n",
    "\n",
    "Using scientific equipment, we can scan for radio waves and discover new pulsar stars. However, some positive detections are caused by radio frequency interference, which makes real detections difficult to find. The main objective of our data analysis is determining if scientific equipment analyzed a real pulsar star or radio frequency interference.<br/> \n",
    "\n",
    "<img src=\"https://media.giphy.com/media/l3dj5M4YLaFww31V6/giphy.gif\" width = \"600\"/>\n",
    "\n",
    "Source: https://media.giphy.com/media/l3dj5M4YLaFww31V6/giphy.gif\n",
    "\n",
    "This leads into our question: \n",
    "__Using pulsar star candidate data recorded by scientific equipment, is a given candidate a true pulsar star or just radio frequency interference?__\n",
    "\n",
    "Each observation in the data set (the <a href=\"https://archive.ics.uci.edu/ml/datasets/HTRU2\">HTRU2 Data Set</a> by Rob Lyon) is a candidate, with 8 continuous variables:<br />\n",
    "1. `mean_of_int_profiles` <br/>\n",
    "2. `sd_of_int_profiles`<br />\n",
    "3. `excess_kurtosis_of_int_profiles`<br />\n",
    "4. `skewness_of_int_profiles`<br />\n",
    "5. `mean_of_curve`<br />\n",
    "6. `sd_of_curve`<br />\n",
    "7. `excess_kurtosis_of_curve`<br />\n",
    "8. `skewness_of_curve`<br />\n",
    "\n",
    "... and one class variable:<br />\n",
    "1. `true_pulsar`\n",
    "\n",
    "The first four of our predictor variables are simple statistics obtained from the integrated pulse profile. Pulse profiles are beams radiated by pulsars which have unique signatures that differ from pulsar to pulsar. \n",
    "\n",
    "The remaining four predictor variables are similar statistics obtained from the DM-SNR curve.  DM-SNR stands for Dispersion Measure/Signal-to-Noise Ratio, which analyzes the signal to noise ratio of pulsar beams in a normalized curve. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22e0d2ef-d10f-4d94-8c9b-dacd87e3402e",
   "metadata": {},
   "source": [
    "### Method and Results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0e226bd-b83f-43c4-9d80-d6cbc59568bd",
   "metadata": {},
   "source": [
    "Description of Methodology: \n",
    "\n",
    "We will use a classifier that utilizes the k nearest neighbor algorithm, which is a type of supervised learning method. The knn algorithmn uses proximity to make classifications or predictions about the grouping of a particular datapoint. Firstly, we will do a preliminary exploratory analysis to get an overview of the dataset. Since we have limited knownledge about the subject of study (pulsar star) while also have a large amount of data and relatively small number of predictors, we will use the forward selection method to aid us in selecting relevant variables to use in our model. After that, we will cross-validation to determine the k values that would give us the best performance. We subsequently used this value to perform the classification and access the accuracy of the our model (with a percentage as well as a confusion matrix).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "faade234-aeb9-47fa-8854-4d63b2ef0920",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "── \u001b[1mAttaching packages\u001b[22m ─────────────────────────────────────── tidyverse 1.3.1 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mggplot2\u001b[39m 3.3.6     \u001b[32m✔\u001b[39m \u001b[34mpurrr  \u001b[39m 0.3.4\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtibble \u001b[39m 3.1.7     \u001b[32m✔\u001b[39m \u001b[34mdplyr  \u001b[39m 1.0.9\n",
      "\u001b[32m✔\u001b[39m \u001b[34mtidyr  \u001b[39m 1.2.0     \u001b[32m✔\u001b[39m \u001b[34mstringr\u001b[39m 1.4.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mreadr  \u001b[39m 2.1.2     \u001b[32m✔\u001b[39m \u001b[34mforcats\u001b[39m 0.5.1\n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ────────────────────────────────────────── tidyverse_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m    masks \u001b[34mstats\u001b[39m::lag()\n",
      "\n",
      "── \u001b[1mAttaching packages\u001b[22m ────────────────────────────────────── tidymodels 1.0.0 ──\n",
      "\n",
      "\u001b[32m✔\u001b[39m \u001b[34mbroom       \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mrsample     \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mdials       \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mtune        \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34minfer       \u001b[39m 1.0.2     \u001b[32m✔\u001b[39m \u001b[34mworkflows   \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mmodeldata   \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34mworkflowsets\u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mparsnip     \u001b[39m 1.0.0     \u001b[32m✔\u001b[39m \u001b[34myardstick   \u001b[39m 1.0.0\n",
      "\u001b[32m✔\u001b[39m \u001b[34mrecipes     \u001b[39m 1.0.1     \n",
      "\n",
      "── \u001b[1mConflicts\u001b[22m ───────────────────────────────────────── tidymodels_conflicts() ──\n",
      "\u001b[31m✖\u001b[39m \u001b[34mscales\u001b[39m::\u001b[32mdiscard()\u001b[39m masks \u001b[34mpurrr\u001b[39m::discard()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mfilter()\u001b[39m   masks \u001b[34mstats\u001b[39m::filter()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mfixed()\u001b[39m  masks \u001b[34mstringr\u001b[39m::fixed()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mdplyr\u001b[39m::\u001b[32mlag()\u001b[39m      masks \u001b[34mstats\u001b[39m::lag()\n",
      "\u001b[31m✖\u001b[39m \u001b[34myardstick\u001b[39m::\u001b[32mspec()\u001b[39m masks \u001b[34mreadr\u001b[39m::spec()\n",
      "\u001b[31m✖\u001b[39m \u001b[34mrecipes\u001b[39m::\u001b[32mstep()\u001b[39m   masks \u001b[34mstats\u001b[39m::step()\n",
      "\u001b[34m•\u001b[39m Dig deeper into tidy modeling with R at \u001b[32mhttps://www.tmwr.org\u001b[39m\n",
      "\n",
      "also installing the dependencies ‘RANN’, ‘ROSE’\n",
      "\n",
      "\n",
      "Updating HTML index of packages in '.Library'\n",
      "\n",
      "Making 'packages.html' ...\n",
      " done\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Importing required libraries\n",
    "\n",
    "library(tidyverse)\n",
    "library(repr)\n",
    "library(tidymodels)\n",
    "install.packages(\"themis\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92660ca6-e564-4923-8df2-d64ab729a8ed",
   "metadata": {},
   "source": [
    "We can download the dataset (https://archive.ics.uci.edu/ml/datasets/HTRU2) and import into JupyterHub."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3e395eb3-3a80-4880-823c-15ebb20ffe21",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message in dir.create(\"data\"):\n",
      "“'data' already exists”\n",
      "\u001b[1mRows: \u001b[22m\u001b[34m17898\u001b[39m \u001b[1mColumns: \u001b[22m\u001b[34m9\u001b[39m\n",
      "\u001b[36m──\u001b[39m \u001b[1mColumn specification\u001b[22m \u001b[36m────────────────────────────────────────────────────────\u001b[39m\n",
      "\u001b[1mDelimiter:\u001b[22m \",\"\n",
      "\u001b[32mdbl\u001b[39m (9): mean_of_int_profiles, sd_of_int_profiles, excess_kurtosis_of_int_pr...\n",
      "\n",
      "\u001b[36mℹ\u001b[39m Use `spec()` to retrieve the full column specification for this data.\n",
      "\u001b[36mℹ\u001b[39m Specify the column types or set `show_col_types = FALSE` to quiet this message.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table 1.0: Snapshot of star data\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 10 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>mean_of_int_profiles</th><th scope=col>sd_of_int_profiles</th><th scope=col>excess_kurtosis_of_int_profiles</th><th scope=col>skewness_of_int_profiles</th><th scope=col>mean_of_curve</th><th scope=col>sd_of_curve</th><th scope=col>excess_kurtosis_of_curve</th><th scope=col>skewness_of_curve</th><th scope=col>true_pulsar</th></tr>\n",
       "\t<tr><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;fct&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>140.56250</td><td>55.68378</td><td>-0.23457141</td><td>-0.6996484</td><td>3.1998328</td><td>19.110426</td><td> 7.975532</td><td> 74.24222</td><td>0</td></tr>\n",
       "\t<tr><td>102.50781</td><td>58.88243</td><td> 0.46531815</td><td>-0.5150879</td><td>1.6772575</td><td>14.860146</td><td>10.576487</td><td>127.39358</td><td>0</td></tr>\n",
       "\t<tr><td>103.01562</td><td>39.34165</td><td> 0.32332837</td><td> 1.0511644</td><td>3.1212375</td><td>21.744669</td><td> 7.735822</td><td> 63.17191</td><td>0</td></tr>\n",
       "\t<tr><td>136.75000</td><td>57.17845</td><td>-0.06841464</td><td>-0.6362384</td><td>3.6429766</td><td>20.959280</td><td> 6.896499</td><td> 53.59366</td><td>0</td></tr>\n",
       "\t<tr><td> 88.72656</td><td>40.67223</td><td> 0.60086608</td><td> 1.1234917</td><td>1.1789298</td><td>11.468720</td><td>14.269573</td><td>252.56731</td><td>0</td></tr>\n",
       "\t<tr><td> 93.57031</td><td>46.69811</td><td> 0.53190485</td><td> 0.4167211</td><td>1.6362876</td><td>14.545074</td><td>10.621748</td><td>131.39400</td><td>0</td></tr>\n",
       "\t<tr><td>119.48438</td><td>48.76506</td><td> 0.03146022</td><td>-0.1121676</td><td>0.9991639</td><td> 9.279612</td><td>19.206230</td><td>479.75657</td><td>0</td></tr>\n",
       "\t<tr><td>130.38281</td><td>39.84406</td><td>-0.15832276</td><td> 0.3895404</td><td>1.2207358</td><td>14.378941</td><td>13.539456</td><td>198.23646</td><td>0</td></tr>\n",
       "\t<tr><td>107.25000</td><td>52.62708</td><td> 0.45268802</td><td> 0.1703474</td><td>2.3319398</td><td>14.486853</td><td> 9.001004</td><td>107.97251</td><td>0</td></tr>\n",
       "\t<tr><td>107.25781</td><td>39.49649</td><td> 0.46588196</td><td> 1.1628771</td><td>4.0794314</td><td>24.980418</td><td> 7.397080</td><td> 57.78474</td><td>0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 10 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " mean\\_of\\_int\\_profiles & sd\\_of\\_int\\_profiles & excess\\_kurtosis\\_of\\_int\\_profiles & skewness\\_of\\_int\\_profiles & mean\\_of\\_curve & sd\\_of\\_curve & excess\\_kurtosis\\_of\\_curve & skewness\\_of\\_curve & true\\_pulsar\\\\\n",
       " <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <fct>\\\\\n",
       "\\hline\n",
       "\t 140.56250 & 55.68378 & -0.23457141 & -0.6996484 & 3.1998328 & 19.110426 &  7.975532 &  74.24222 & 0\\\\\n",
       "\t 102.50781 & 58.88243 &  0.46531815 & -0.5150879 & 1.6772575 & 14.860146 & 10.576487 & 127.39358 & 0\\\\\n",
       "\t 103.01562 & 39.34165 &  0.32332837 &  1.0511644 & 3.1212375 & 21.744669 &  7.735822 &  63.17191 & 0\\\\\n",
       "\t 136.75000 & 57.17845 & -0.06841464 & -0.6362384 & 3.6429766 & 20.959280 &  6.896499 &  53.59366 & 0\\\\\n",
       "\t  88.72656 & 40.67223 &  0.60086608 &  1.1234917 & 1.1789298 & 11.468720 & 14.269573 & 252.56731 & 0\\\\\n",
       "\t  93.57031 & 46.69811 &  0.53190485 &  0.4167211 & 1.6362876 & 14.545074 & 10.621748 & 131.39400 & 0\\\\\n",
       "\t 119.48438 & 48.76506 &  0.03146022 & -0.1121676 & 0.9991639 &  9.279612 & 19.206230 & 479.75657 & 0\\\\\n",
       "\t 130.38281 & 39.84406 & -0.15832276 &  0.3895404 & 1.2207358 & 14.378941 & 13.539456 & 198.23646 & 0\\\\\n",
       "\t 107.25000 & 52.62708 &  0.45268802 &  0.1703474 & 2.3319398 & 14.486853 &  9.001004 & 107.97251 & 0\\\\\n",
       "\t 107.25781 & 39.49649 &  0.46588196 &  1.1628771 & 4.0794314 & 24.980418 &  7.397080 &  57.78474 & 0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 10 × 9\n",
       "\n",
       "| mean_of_int_profiles &lt;dbl&gt; | sd_of_int_profiles &lt;dbl&gt; | excess_kurtosis_of_int_profiles &lt;dbl&gt; | skewness_of_int_profiles &lt;dbl&gt; | mean_of_curve &lt;dbl&gt; | sd_of_curve &lt;dbl&gt; | excess_kurtosis_of_curve &lt;dbl&gt; | skewness_of_curve &lt;dbl&gt; | true_pulsar &lt;fct&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 140.56250 | 55.68378 | -0.23457141 | -0.6996484 | 3.1998328 | 19.110426 |  7.975532 |  74.24222 | 0 |\n",
       "| 102.50781 | 58.88243 |  0.46531815 | -0.5150879 | 1.6772575 | 14.860146 | 10.576487 | 127.39358 | 0 |\n",
       "| 103.01562 | 39.34165 |  0.32332837 |  1.0511644 | 3.1212375 | 21.744669 |  7.735822 |  63.17191 | 0 |\n",
       "| 136.75000 | 57.17845 | -0.06841464 | -0.6362384 | 3.6429766 | 20.959280 |  6.896499 |  53.59366 | 0 |\n",
       "|  88.72656 | 40.67223 |  0.60086608 |  1.1234917 | 1.1789298 | 11.468720 | 14.269573 | 252.56731 | 0 |\n",
       "|  93.57031 | 46.69811 |  0.53190485 |  0.4167211 | 1.6362876 | 14.545074 | 10.621748 | 131.39400 | 0 |\n",
       "| 119.48438 | 48.76506 |  0.03146022 | -0.1121676 | 0.9991639 |  9.279612 | 19.206230 | 479.75657 | 0 |\n",
       "| 130.38281 | 39.84406 | -0.15832276 |  0.3895404 | 1.2207358 | 14.378941 | 13.539456 | 198.23646 | 0 |\n",
       "| 107.25000 | 52.62708 |  0.45268802 |  0.1703474 | 2.3319398 | 14.486853 |  9.001004 | 107.97251 | 0 |\n",
       "| 107.25781 | 39.49649 |  0.46588196 |  1.1628771 | 4.0794314 | 24.980418 |  7.397080 |  57.78474 | 0 |\n",
       "\n"
      ],
      "text/plain": [
       "   mean_of_int_profiles sd_of_int_profiles excess_kurtosis_of_int_profiles\n",
       "1  140.56250            55.68378           -0.23457141                    \n",
       "2  102.50781            58.88243            0.46531815                    \n",
       "3  103.01562            39.34165            0.32332837                    \n",
       "4  136.75000            57.17845           -0.06841464                    \n",
       "5   88.72656            40.67223            0.60086608                    \n",
       "6   93.57031            46.69811            0.53190485                    \n",
       "7  119.48438            48.76506            0.03146022                    \n",
       "8  130.38281            39.84406           -0.15832276                    \n",
       "9  107.25000            52.62708            0.45268802                    \n",
       "10 107.25781            39.49649            0.46588196                    \n",
       "   skewness_of_int_profiles mean_of_curve sd_of_curve excess_kurtosis_of_curve\n",
       "1  -0.6996484               3.1998328     19.110426    7.975532               \n",
       "2  -0.5150879               1.6772575     14.860146   10.576487               \n",
       "3   1.0511644               3.1212375     21.744669    7.735822               \n",
       "4  -0.6362384               3.6429766     20.959280    6.896499               \n",
       "5   1.1234917               1.1789298     11.468720   14.269573               \n",
       "6   0.4167211               1.6362876     14.545074   10.621748               \n",
       "7  -0.1121676               0.9991639      9.279612   19.206230               \n",
       "8   0.3895404               1.2207358     14.378941   13.539456               \n",
       "9   0.1703474               2.3319398     14.486853    9.001004               \n",
       "10  1.1628771               4.0794314     24.980418    7.397080               \n",
       "   skewness_of_curve true_pulsar\n",
       "1   74.24222         0          \n",
       "2  127.39358         0          \n",
       "3   63.17191         0          \n",
       "4   53.59366         0          \n",
       "5  252.56731         0          \n",
       "6  131.39400         0          \n",
       "7  479.75657         0          \n",
       "8  198.23646         0          \n",
       "9  107.97251         0          \n",
       "10  57.78474         0          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Downloading from url \n",
    "url <- \"https://archive.ics.uci.edu/ml/machine-learning-databases/00372/HTRU2.zip\"\n",
    "dir.create(\"data\")\n",
    "file <- download.file(url, \"data/HTRU2.zip\")\n",
    "\n",
    "# Because the data we need is in a .zip file, we use the unzip() function in order to access \"HTRU_2.csv\"\n",
    "star_data <- read_csv(unzip(\"data/HTRU2.zip\", files = \"HTRU_2.csv\", exdir = \"data/\"), \n",
    "            col_names = c(\"mean_of_int_profiles\", \"sd_of_int_profiles\", \"excess_kurtosis_of_int_profiles\",\n",
    "            \"skewness_of_int_profiles\", \"mean_of_curve\", \"sd_of_curve\", \n",
    "            \"excess_kurtosis_of_curve\", \"skewness_of_curve\", \"true_pulsar\")) |>\n",
    "    mutate(true_pulsar = as_factor(true_pulsar))\n",
    "\n",
    "print(\"Table 1.0: Snapshot of star data\")\n",
    "\n",
    "slice(star_data, 1:10)\n",
    "# Below is a snapshot of the star data we will be working with"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3c1eebf-a3e2-4d3c-8001-661df3f9f460",
   "metadata": {},
   "source": [
    "#### Preliminary Exploratory Data Analysis\n",
    "\n",
    "Before we begin classification, let's have an overview of our dataset. We will look at the number and percentage of pulsar and non-pulsar observations in our dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "42407232-42f5-434c-9b5f-ce961a34b8d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table 1.1: Showing the proportions of true and false pulsars\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 3</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>true_pulsar</th><th scope=col>count</th><th scope=col>percentage</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>16259</td><td>90.842552</td></tr>\n",
       "\t<tr><td>1</td><td> 1639</td><td> 9.157448</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 3\n",
       "\\begin{tabular}{lll}\n",
       " true\\_pulsar & count & percentage\\\\\n",
       " <fct> & <int> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 16259 & 90.842552\\\\\n",
       "\t 1 &  1639 &  9.157448\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 3\n",
       "\n",
       "| true_pulsar &lt;fct&gt; | count &lt;int&gt; | percentage &lt;dbl&gt; |\n",
       "|---|---|---|\n",
       "| 0 | 16259 | 90.842552 |\n",
       "| 1 |  1639 |  9.157448 |\n",
       "\n"
      ],
      "text/plain": [
       "  true_pulsar count percentage\n",
       "1 0           16259 90.842552 \n",
       "2 1            1639  9.157448 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Summarizing data into table counting the number of true and false pulsars\n",
    "\n",
    "num_obs <- nrow(star_data)\n",
    "\n",
    "pulsar_frequency <- star_data |>\n",
    "    group_by(true_pulsar) |>\n",
    "    summarize(count = n(),\n",
    "             percentage = n() / num_obs * 100)\n",
    "\n",
    "print(\"Table 1.1: Showing the proportions of true and false pulsars\")\n",
    "\n",
    "pulsar_frequency"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55a0241d-be41-464c-b5cb-0bbee973be9f",
   "metadata": {},
   "source": [
    "Here, we can see that there is a class imbalance - there are about 10 times more false pulsars than true pulsars! To solve this, we oversample the true pulsars in order to ensure that our classification is not skewed towards predicting false.\n",
    "\n",
    "The first step is to split our data into a training and a testing set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9ae8fb6e-0a4c-41d4-bc45-36b50f9875bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DO NOT REMOVE\n",
    "set.seed(9999) \n",
    "\n",
    "# Splitting data into training and testing, with true_pulsar as the strata\n",
    "pulsar_split <- initial_split(star_data, prop = 0.75, strata = true_pulsar)  \n",
    "pulsar_train <- training(pulsar_split)   \n",
    "pulsar_test <- testing(pulsar_split)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d14604d-3ecd-4ac1-84d9-89e443fbadd2",
   "metadata": {},
   "source": [
    "We will first take a closer look at our training data. For now, our intended predictor variables are going to be **mean_of_int_profiles** and **mean_of_curve**, but we will decide on our predictor variables later by using forward selection."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e9a7f14d-27ab-4061-ba8d-5521a9ca9e16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create upsampling recipe\n",
    "ups_recipe <- recipe(true_pulsar ~ ., data = pulsar_train) |>\n",
    "  themis::step_upsample(true_pulsar, over_ratio = 1, skip = FALSE) |>\n",
    "  prep()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c93b386f-69fe-469d-acef-b981dfaa5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table 1.2: Showing the proportions of true and false pulsars after upsampling (for training set)\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 2</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>true_pulsar</th><th scope=col>number</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;int&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>12207</td></tr>\n",
       "\t<tr><td>1</td><td>12207</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 2\n",
       "\\begin{tabular}{ll}\n",
       " true\\_pulsar & number\\\\\n",
       " <fct> & <int>\\\\\n",
       "\\hline\n",
       "\t 0 & 12207\\\\\n",
       "\t 1 & 12207\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 2\n",
       "\n",
       "| true_pulsar &lt;fct&gt; | number &lt;int&gt; |\n",
       "|---|---|\n",
       "| 0 | 12207 |\n",
       "| 1 | 12207 |\n",
       "\n"
      ],
      "text/plain": [
       "  true_pulsar number\n",
       "1 0           12207 \n",
       "2 1           12207 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Actually using recipe to create upsampled data set\n",
    "pulsar_train_upsampled <- bake(ups_recipe, pulsar_train)\n",
    "\n",
    "print(\"Table 1.2: Showing the proportions of true and false pulsars after upsampling (for training set)\")\n",
    "\n",
    "pulsar_train_upsampled |>\n",
    "  group_by(true_pulsar) |>\n",
    "  summarize(number = n())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49dcdd3b-2338-4d73-aa82-550086b06635",
   "metadata": {},
   "source": [
    "Now, we can explore our upsampled data further. Let's find the average values of our intended predictor variables for both true and false pulsars. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "09fca64f-3eed-4300-bc2a-1e1f063321c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1] \"Table 1.3: Showing the average of our intended predictor variables\"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"dataframe\">\n",
       "<caption>A tibble: 2 × 9</caption>\n",
       "<thead>\n",
       "\t<tr><th scope=col>true_pulsar</th><th scope=col>avg_mean_of_int_profiles</th><th scope=col>avg_mean_of_curve</th><th scope=col>sd_of_mean_of_int_profiles</th><th scope=col>sd_of_mean_of_curve</th><th scope=col>max_mean_of_int_profiles</th><th scope=col>max_mean_of_curve</th><th scope=col>min_mean_of_int_profiles</th><th scope=col>min_mean_of_curve</th></tr>\n",
       "\t<tr><th scope=col>&lt;fct&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th><th scope=col>&lt;dbl&gt;</th></tr>\n",
       "</thead>\n",
       "<tbody>\n",
       "\t<tr><td>0</td><td>116.68182</td><td> 8.886237</td><td>17.49323</td><td>24.42917</td><td>192.6172</td><td>223.3921</td><td>33.21094</td><td>0.2132107</td></tr>\n",
       "\t<tr><td>1</td><td> 56.41515</td><td>50.493516</td><td>29.88371</td><td>45.51590</td><td>139.2578</td><td>184.5259</td><td> 5.81250</td><td>0.4866221</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "A tibble: 2 × 9\n",
       "\\begin{tabular}{lllllllll}\n",
       " true\\_pulsar & avg\\_mean\\_of\\_int\\_profiles & avg\\_mean\\_of\\_curve & sd\\_of\\_mean\\_of\\_int\\_profiles & sd\\_of\\_mean\\_of\\_curve & max\\_mean\\_of\\_int\\_profiles & max\\_mean\\_of\\_curve & min\\_mean\\_of\\_int\\_profiles & min\\_mean\\_of\\_curve\\\\\n",
       " <fct> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl> & <dbl>\\\\\n",
       "\\hline\n",
       "\t 0 & 116.68182 &  8.886237 & 17.49323 & 24.42917 & 192.6172 & 223.3921 & 33.21094 & 0.2132107\\\\\n",
       "\t 1 &  56.41515 & 50.493516 & 29.88371 & 45.51590 & 139.2578 & 184.5259 &  5.81250 & 0.4866221\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "\n",
       "A tibble: 2 × 9\n",
       "\n",
       "| true_pulsar &lt;fct&gt; | avg_mean_of_int_profiles &lt;dbl&gt; | avg_mean_of_curve &lt;dbl&gt; | sd_of_mean_of_int_profiles &lt;dbl&gt; | sd_of_mean_of_curve &lt;dbl&gt; | max_mean_of_int_profiles &lt;dbl&gt; | max_mean_of_curve &lt;dbl&gt; | min_mean_of_int_profiles &lt;dbl&gt; | min_mean_of_curve &lt;dbl&gt; |\n",
       "|---|---|---|---|---|---|---|---|---|\n",
       "| 0 | 116.68182 |  8.886237 | 17.49323 | 24.42917 | 192.6172 | 223.3921 | 33.21094 | 0.2132107 |\n",
       "| 1 |  56.41515 | 50.493516 | 29.88371 | 45.51590 | 139.2578 | 184.5259 |  5.81250 | 0.4866221 |\n",
       "\n"
      ],
      "text/plain": [
       "  true_pulsar avg_mean_of_int_profiles avg_mean_of_curve\n",
       "1 0           116.68182                 8.886237        \n",
       "2 1            56.41515                50.493516        \n",
       "  sd_of_mean_of_int_profiles sd_of_mean_of_curve max_mean_of_int_profiles\n",
       "1 17.49323                   24.42917            192.6172                \n",
       "2 29.88371                   45.51590            139.2578                \n",
       "  max_mean_of_curve min_mean_of_int_profiles min_mean_of_curve\n",
       "1 223.3921          33.21094                 0.2132107        \n",
       "2 184.5259           5.81250                 0.4866221        "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Creating another table that shows the average of our intended predictor variables\n",
    "pulsar_predictors <- pulsar_train_upsampled |>\n",
    "    group_by(true_pulsar) |>\n",
    "    summarize(avg_mean_of_int_profiles = mean(mean_of_int_profiles),\n",
    "              avg_mean_of_curve = mean(mean_of_curve),\n",
    "              sd_of_mean_of_int_profiles = sd(mean_of_int_profiles),\n",
    "              sd_of_mean_of_curve = sd(mean_of_curve),\n",
    "              max_mean_of_int_profiles = max(mean_of_int_profiles),\n",
    "              max_mean_of_curve = max(mean_of_curve),\n",
    "              min_mean_of_int_profiles = min(mean_of_int_profiles),\n",
    "              min_mean_of_curve = min(mean_of_curve))\n",
    "\n",
    "print(\"Table 1.3: Showing the average of our intended predictor variables\")\n",
    "\n",
    "pulsar_predictors"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbb3786b-fa71-4239-8da1-fb94016eead4",
   "metadata": {},
   "source": [
    "From this, we note that true pulsars have a mean of integrated profile around 57 and a mean of curve around 50, while false pulsars have a mean of integrated profile around 117 and a mean of curve around 9."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "717e8070-df71-4b25-8e00-043c564176c7",
   "metadata": {},
   "source": [
    "#### Preminary Visualization\n",
    "\n",
    "We will now perform some visualization to get a sense of how the data looks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3aa758c-0af9-448a-bfb4-9ee96617bb67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Next, we will begin some visualization of our training data. We start by building scatter plots with Mean of Integrated Profiles on the x-axis \n",
    "# and Mean of DM-SNR Curve on the y-axis, with True Pulsars labeled by colour. We will build one with the original star data, and one with the \n",
    "# upsampled data.\n",
    "\n",
    "# DO NOT REMOVE\n",
    "set.seed(9999) \n",
    "\n",
    "# Visualizing the mean of integrated profiles and the mean of DM-SNR curve with colour to differentiate true pulsars\n",
    "options(repr.plot.width = 12, repr.plot.height = 6)\n",
    "\n",
    "pulsar_plot <- pulsar_train |>\n",
    "    ggplot(aes(x = mean_of_int_profiles, y = mean_of_curve)) +\n",
    "           geom_point(aes(color = true_pulsar), alpha = 0.6) +\n",
    "           labs(x = \"Mean of Integrated Profiles\", y = \"Mean of DM-SNR Curve\", color = \"Class\") +\n",
    "           scale_color_discrete(labels=c('Radio Frequency Interference', 'True Pulsar')) + \n",
    "           theme(text = element_text(size = 20)) +\n",
    "           ggtitle(\"Scatter plot for original training data\")\n",
    "\n",
    "print(\"Figure 1.0: Scatter plot for original training data\")\n",
    "\n",
    "pulsar_plot\n",
    "\n",
    "pulsar_plot_upsampled <- pulsar_train_upsampled |>\n",
    "    ggplot(aes(x = mean_of_int_profiles, y = mean_of_curve)) +\n",
    "           geom_point(aes(color = true_pulsar), alpha = 0.6) +\n",
    "           labs(x = \"Mean of Integrated Profiles\", y = \"Mean of DM-SNR Curve\", color = \"Class\") +\n",
    "           scale_color_discrete(labels=c('Radio Frequency Interference', 'True Pulsar')) + \n",
    "           theme(text = element_text(size = 18)) +\n",
    "           ggtitle(\"Scatter plot for upsampled training data\")\n",
    "\n",
    "print(\"Figure 1.1: Scatter plot for upsampled training data\")\n",
    "\n",
    "pulsar_plot_upsampled"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b69ec2a9-993b-440a-affd-f99556312382",
   "metadata": {},
   "source": [
    "Although the plots appear similar, we can see that for the upsampled plot, True Pulsars are more prominent near the bottom instead of being overshadowed by radio frequency interference."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19b465e0-37fe-430c-8e91-951795efef5c",
   "metadata": {},
   "source": [
    "#### Predictor variable selection\n",
    "\n",
    "For our project we will use forward selection to select predictor variables to be used in the model. We start with an empty model and iteratively add variables that give the best performance to the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7f02f1-0135-428c-9bfa-bba81a1018b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "names <- colnames(pulsar_train_upsampled |> select(-true_pulsar))\n",
    "\n",
    "formula <- paste(\"true_pulsar\", \"~\", paste(names, collapse=\"+\"))\n",
    "formula"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4db2f502-1ff3-4b01-8f82-5da812e41590",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an empty tibble to store the results\n",
    "accuracies <- tibble(size = integer(), \n",
    "                     model_string = character(), \n",
    "                     accuracy = numeric())\n",
    "\n",
    "# create a model specification\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", \n",
    "                             neighbors = tune()) |>\n",
    "     set_engine(\"kknn\") |>\n",
    "     set_mode(\"classification\")\n",
    "\n",
    "# create a 5-fold cross-validation object\n",
    "star_vfold <- vfold_cv(pulsar_train_upsampled, v = 5, strata = true_pulsar)\n",
    "\n",
    "# store the total number of predictors\n",
    "n_total <- length(names)\n",
    "\n",
    "# stores selected predictors\n",
    "selected <- c()\n",
    "\n",
    "# for (i in 1:n_total) {\n",
    "#     accs <- list()\n",
    "#     models <- list()\n",
    "#     for (j in 1:length(names)) {\n",
    "#         preds_new <- c(selected, names[[j]])\n",
    "#         model_string <- paste(\"true_pulsar\", \"~\", paste(preds_new, collapse=\"+\"))\n",
    "#\n",
    "#         star_recipe <- recipe(as.formula(model_string), \n",
    "#                                 data = pulsar_train_upsampled) |>\n",
    "#                           step_scale(all_predictors()) |>\n",
    "#                           step_center(all_predictors())\n",
    "#\n",
    "#         acc <- workflow() |>\n",
    "#           add_recipe(star_recipe) |>\n",
    "#           add_model(knn_spec) |>\n",
    "#           tune_grid(resamples = star_vfold, grid = 10) |>\n",
    "#           collect_metrics() |>\n",
    "#           filter(.metric == \"accuracy\") |>\n",
    "#           summarize(mx = max(mean))\n",
    "#         acc <- acc$mx |> unlist()\n",
    "#\n",
    "#         accs[[j]] <- acc\n",
    "#         models[[j]] <- model_string\n",
    "#     }\n",
    "#     jstar <- which.max(unlist(accs))\n",
    "#     accuracies <- accuracies |> \n",
    "#       add_row(size = i, \n",
    "#               model_string = models[[jstar]], \n",
    "#               accuracy = accs[[jstar]])\n",
    "#     selected <- c(selected, names[[jstar]])\n",
    "#     names <- names[-jstar]\n",
    "# }\n",
    "#\n",
    "# accuracies\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00f5e293-69e5-45d4-905e-38cb54af4580",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Table 2.0: Predictor variables combinations and corresponding accuracies\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87cdd978-7ce2-4172-ad78-dc781623129c",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"data/dsci_project.png\" width = \"1100\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c348f7-c7c5-4568-8841-5a3665b279bd",
   "metadata": {},
   "source": [
    "In order to save time, we have attached  an image of the result of forward selection and commented out the code. From what we obtained , we can see that using the three variables excess_kurtosis_of_int_profiles, mean_of_int_profiles and skewness_of_int_profiles  in our model would give the best performance. Therefore we will use these variables as predictors. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44005cbc-2bb6-41b9-a41b-7811d2175e29",
   "metadata": {},
   "source": [
    "#### Tuning the Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8865a9e-e0c3-45bf-905c-3903cdd6c158",
   "metadata": {},
   "source": [
    "We begin by creating a 5-fold cross validation to find the optimal *k* value:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47720564-c157-48c8-bb22-18bd707b52a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_vfold <- vfold_cv(pulsar_train_upsampled, v = 5, strata = true_pulsar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f3f4332-b69b-43c3-90f0-aae6d59f5a77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a model and recipe for our tuning classification:\n",
    "pulsar_recipe <- recipe(true_pulsar ~ excess_kurtosis_of_int_profiles + mean_of_int_profiles + skewness_of_int_profiles , data = pulsar_train_upsampled) |>\n",
    "    step_center(all_predictors()) |>\n",
    "    step_scale(all_predictors()) \n",
    "\n",
    "knn_spec <- nearest_neighbor(weight_func = \"rectangular\", neighbors = tune()) |>\n",
    "    set_engine(\"kknn\") |> \n",
    "    set_mode(\"classification\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5665bd56-303b-4784-aedf-7f6fd5c71c20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# creating intervals of k values to test\n",
    "k_vals <- tibble(neighbors = seq(from = 1, to = 10, by = 1))\n",
    "\n",
    "# Combining everything into a workflow\n",
    "knn_results <- workflow() |>\n",
    "  add_recipe(pulsar_recipe) |>\n",
    "  add_model(knn_spec) |>\n",
    "  tune_grid(resamples = pulsar_vfold, grid = k_vals) |>\n",
    "  collect_metrics()\n",
    "\n",
    "print(\"Table 2.1: Cross validation accuracy results\")\n",
    "\n",
    "knn_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4bc41f34-277c-4a68-bcb0-91982a514558",
   "metadata": {},
   "source": [
    "Now, we will analyze and plot the accuracies for these k values in order to choose the best k."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2d68d7e-b749-4393-bade-42791c663272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, we will be analyzing the accuracies at different k values.\n",
    "accuracies <- knn_results |> \n",
    "       filter(.metric == \"accuracy\")\n",
    "\n",
    "accuracy_versus_k <- ggplot(accuracies, aes(x = neighbors, y = mean))+\n",
    "       geom_point() +\n",
    "       geom_line() +\n",
    "       labs(x = \"Neighbors\", y = \"Accuracy Estimate\") +\n",
    "       theme(text = element_text(size = 20)) +\n",
    "       scale_x_continuous(breaks = seq(0, 14, by = 1))   # adjusting the x-axis\n",
    "\n",
    "print(\"Figure 2.0: Line plot for accuracy estimates at various k values\")\n",
    "\n",
    "accuracy_versus_k"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07fcdbb-c636-4c69-b3c4-43f8bdbb3d44",
   "metadata": {},
   "source": [
    "From this graph, we see that having a k value of 1 and 2 results in the highest accuracy estimate. However, we feel that using 1 as our k value is too extreme and may produce problems in our tests, such as overfitting. For these reasons, we will use a k value of 2 for our classification model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c43278d4-2c7c-47d8-a822-77a606bd9a76",
   "metadata": {},
   "source": [
    "#### Performing the classification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8cd50967-8c5f-43cc-9c3a-cce8a91c90e5",
   "metadata": {},
   "source": [
    "Now, we will finally create our knn classification model with our carefully chosen predictor variables and k value."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb05408c-36a9-41f1-8d36-7ace9dc74443",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_training_model <- nearest_neighbor(weight_func = \"rectangular\", neighbors = 2) |> \n",
    "    set_engine(\"kknn\") |> \n",
    "    set_mode(\"classification\") # training model with k = 2 neighbors (found through 5-fold cross validation)\n",
    "\n",
    "pulsar_fit <- workflow() |>\n",
    "    add_recipe(pulsar_recipe) |>\n",
    "    add_model(pulsar_training_model) |>\n",
    "    fit(data = pulsar_train_upsampled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e739ef6-3a2a-44d2-a779-6fdaf6eb9102",
   "metadata": {},
   "source": [
    "With this classification model set up, we can now test it against our testing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3841946-ee8f-4175-b926-d10c20bb544e",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_test_predictions <- predict(pulsar_fit, pulsar_test) |> \n",
    "    bind_cols(pulsar_test) # prediction set\n",
    "\n",
    "pulsar_prediction_accuracy <- pulsar_test_predictions |>\n",
    "    metrics(truth = true_pulsar, estimate = .pred_class) # accuracy of predictions\n",
    "\n",
    "print(\"Table 2.2: The accuracy of our classification on testing data\")\n",
    "\n",
    "pulsar_prediction_accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13490e0a-d084-45a7-8ce7-0c6a66fbd727",
   "metadata": {},
   "outputs": [],
   "source": [
    "pulsar_mat <- pulsar_test_predictions |>\n",
    "    conf_mat(truth = true_pulsar, estimate = .pred_class)\n",
    "\n",
    "print(\"Table 2.3: A confusion matrix for true and false pulsar predictions\")\n",
    "\n",
    "pulsar_mat # confusion matrix which helps us find that 4,293 of our 4,475 observations were labelled correctly "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87a7e623-7909-4aaf-9788-a9e805744f71",
   "metadata": {},
   "source": [
    "### Discussion"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6de262e5-5b00-48cd-91a8-9a0a487e48ae",
   "metadata": {},
   "source": [
    "__What did we find?__\n",
    "We found that by using excess_kurtosis_of_int_profiles, mean_of_int_profiles and skewness_of_int_profiles, we can accurately predict whether a reading is a pulsar or just interference 96.6% of the time (4323/4475).  This is a very accurate classifier which we believe can be very helpful in saving time for scientists.  Using this classification model, scientists would not need to confirm if every reading is a real pulsar and could rather use the model to confirm readings.\n",
    "\n",
    "__Is this what we expected to find?__\n",
    "Yes and No.  We expected that we would find a model that would predict the occurrence of a pulsar well but we never expected it to predict it with the accuracy we achieved.  Looking at the article by Stephen Allwright, a data scientist at ODA, an acceptable level of accuracy within most industries is 70 to 90% (Allright, 2022). This is around where we thought our model would be. The 95.9% accuracy we achieved was far superior to the 90% standard, which was a pleasant surprise.\n",
    "\n",
    "There are several possible reasons why our accuracy was so high. The first one is that we followed all necessary procedures in order to optimize our classification model's accuracy. For example, we recognized the need for upsampling of data, and we utilized forward selection to mathematically choose the best possible combination of prediction variables. However, another reason for this high accuracy could be due to the nature of our data. The star dataset we have been working with is quite large, and so this reduces the impact that unlucky data points have on our accuracy. We can also infer that there is some kind of structure/pattern to our data points based on class, which is what allows our classifier to predict so accurately.\n",
    "\n",
    "__What are the impacts of this finding?__\n",
    "As outlined in the academic thesis paper \"why are pulsars hard to find?\", the most difficult part of identifying a pulsar is sifting through the enormous amount of data that is collected by scientific equipment (Robert James, 2016). Robert Lyon from the school of computer science at Manchester University likens finding true pulsar readings to finding a needle in a haystack.  Therefore, With the ability to confidently classify whether a star is a pulsar or not, scientists could make enormous strides in astronomy. By weeding out the fake pulsars and focusing only on the real ones efficiently with a model, scientists can more accurately study what is happening inside real pulsars while saving time. Since neutron stars (which pulsars are) are the densest material in the universe, studying them can lead to enormous discoveries related to the physics of the universe. Also, by weeding out the fake pulsars, scientists can focus on the real pulsars and calculate cosmic distances.  This is because pulsar stars blink at regular intervals rivalled only by atomic clocks (Calla, 2016).  Overall, the ability to accurately predict whether a \"pulsar event\" in data is real or just interference is a major step in studying the universe beyond our own planet.\n",
    "\n",
    "__What future questions are there?__\n",
    "One big question is can this model be applied to universes outside our own? If there are pulsar stars in our universe, there are likely stars like this in others.  Would the same algorithm for finding these stars apply outside our own universe?\n",
    "\n",
    "Also, we must question if there are more accurate predictor variables that would work better that have not yet been measured. This also brings up, can we tune equipment in the field to also track in real-time whether a reading is real or just interference and filter it right away so scientists don't need to study it?\n",
    "\n",
    "Given that this is just a predictive algorithm to determine if it is pulsar or interference, we must question the validity of the data and if the scientists behind it accurately classified the pulsars."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "814325b7-bf64-47ca-95cd-5534de2c740a",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2aa82b3-d620-4151-86ee-c459251d28de",
   "metadata": {},
   "source": [
    "Cofield, Calla. “What Are Pulsars?” Space.com, Space, 22 Apr. 2016, https://www.space.com/32661-pulsars.html. \n",
    "\n",
    "\n",
    "Stephen Allwright. “What Is a Good Accuracy Score? Simply Explained.” Stephen Allwright, Stephen Allwright, 10 Aug. 2022, https://stephenallwright.com/good-accuracy-score/. \n",
    "\n",
    "Lyon, Robert James. “Why Are Pulsars Hard to Find? - University of Manchester.” WHY ARE PULSARS HARD TO FIND?, 2022, https://www.research.manchester.ac.uk/portal/files/54588348/FULL_TEXT.PDF. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efa509b1-71a4-417f-b079-64ac1c3507b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "R",
   "language": "R",
   "name": "ir"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "4.1.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
